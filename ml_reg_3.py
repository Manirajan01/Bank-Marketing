# -*- coding: utf-8 -*-
"""Ml_reg_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jsreMbOy8PPJb39F3L0saHFY7ETblKCN

!['image'](https://www.welcome-center-malta.com/wp-content/uploads/2018/04/personal-bank-loan-e1531398405823.jpg)

### Problem :
Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers. Here they have provided a partial data set.

## About this Dataset


Among all industries, insurance domain has the largest use of analytics & data science methods. This data set would provide you enough taste of working on data sets from insurance companies, what challenges are faced, what strategies are used, which variables influence the outcome etc. This is a classification problem. The data has 615 rows and 13 columns.

 ### columns
Loan_ID ,Gender, Married, Dependents, Education,
       Self_Employed, ApplicantIncome, CoapplicantIncome, LoanAmount,
       Loan_Amount_Term, Credit_History, Property_Area, Loan_Status

## Import libraries
"""

import pandas as pd
from google.colab import drive
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pylab import rcParams
rcParams['figure.figsize'] = (12,6)
sns.set()
from sklearn.model_selection import train_test_split

"""## load dataset"""

drive.mount('/content/drive')

data = pd.read_csv('/content/drive/MyDrive/dataset/loan_data.csv')

"""## Data Describe"""

data.head()

data.shape

data.columns

data.info()

data.duplicated().sum()

df = data # give your dataframe name
missing_value= df.isnull().sum() 
percentage = (100 * df.isnull().sum() / len(df)).round(2).sort_values() 
data_types = df.dtypes
missing_values_table = pd.concat([missing_value, percentage, data_types], axis=1)
miss_val = missing_values_table.rename(columns = {0 : 'Missing Values',1 : 'Percentage',2 : 'Data Types'})
miss_vals=miss_val.sort_values(by='Percentage',ascending=False)
miss_vals1=miss_vals[miss_vals["Missing Values"]!=0]
# miss_vals1
miss_vals1.style.background_gradient(cmap='seismic')

"""## EDA

### UNIVERIATE ANALYSIS

###  Independent Variable (CATEGORICAL)
"""

c_data = data.select_dtypes(include='object')
c_data.head()

c_data.describe().T

for columns in c_data:
  print(f'{columns}:{c_data[columns].unique()}')
  print("\n=================================\n")

"""### Target Variable"""

plt.figure(figsize=(8,6))
ax = sns.countplot(x='Loan_Status', data=data)
for p in ax.patches:
  ax.annotate('{:}'.format(p.get_height()), (p.get_x()+0.30, p.get_height()+0.01))
plt.title('Loan Status')
plt.show()

c_data['Loan_Status'].value_counts(normalize=True)

plt.figure(figsize=(25,12))
for i in range(7):
  plt.subplot(2,4,i+1)
  ax=sns.countplot(data=c_data,x=c_data.columns[i])
  for p in ax.patches:
    ax.annotate('{:}'.format(p.get_height()), (p.get_x()+0.30, p.get_height()+0.01))

"""1. The number of approved loans is higher compared to rejected loans
2. the number of male applicants is higher compared to female applicants.
3. The number of applicants that has been married is higher compared to applicants that hasn't married.
4. The number of applicants that has been graduated is higher compared to applicants that hasn't graduated.
5. The number of applicants that are not self employed is higher compared to applicants that are self employed.
6. This column has a balanced distribution between Urban, Rural, and Semiurban property area
7. The number of applicants that have good credit history is higher compared to applicants that have bad credit history

## Independent Variable (Numerical)
"""

n_data = data.select_dtypes(exclude = "object")
n_data.head()

n_data.describe().T

for columns in n_data:
  print(f'{columns}:{n_data[columns].unique()}')
  print("\n==============================\n")

n_data['LoanAmount'].describe()

n_data['Loan_Amount_Term'].describe()

y=n_data[(n_data['LoanAmount']>168)&(n_data['Loan_Amount_Term']>360)]
y

n_data.loc[1]

"""### Histogram Analysis"""

plt.figure(figsize=(25,12))
for i in range(5):
  plt.subplot(2,3,i+1)
  sns.distplot(n_data[n_data.columns[i]])
  plt.axvline(n_data[n_data.columns[i]].mean(),color='r')
  plt.axvline(n_data[n_data.columns[i]].median(),color='k',linestyle='--')

"""### Boxplot Analysis

"""

plt.figure(figsize=(25,12))
for i in range(3):
  plt.subplot(2,3,i+1)
  sns.boxplot(data=n_data,x=n_data.columns[i])

"""## Bivariate Analysis

### Categorical Independent Variable vs Target Variable
"""

Gender = pd.crosstab(index=data['Gender'],columns=data['Loan_Status'])
Gender

Gender.sum(1).astype(float)

female_Y = round((75/112)*100,2)
print("Percentage of Female applicants whose application is approved: {}%".format(female_Y))
male_Y = round((339/489)*100,2)
print("Percentage of Male applicants whose application is approved: {}%".format(male_Y))

# marital status and Loan status
sns.countplot(x='Married',hue='Loan_Status', data=data)

# education and Loan Status

sns.countplot(x='Education',hue='Loan_Status', data=data)

# Credit_History and Loan Status

sns.countplot(x='Credit_History',hue='Loan_Status', data=data)

# Dependents and Loan Status

sns.countplot(x='Dependents',hue='Loan_Status', data=data)

# Self_Employed and Loan Status

sns.countplot(x='Self_Employed',hue='Loan_Status', data=data)

# Property_Area and Loan Status

sns.countplot(x='Property_Area',hue='Loan_Status', data=data)

"""## Numerical Independent Variable vs Target Variable"""

data.groupby('Loan_Status').mean()

data.groupby('Loan_Status').mean().plot.bar()
plt.legend(bbox_to_anchor=(1,1),loc='upper left')

sns.heatmap(data=n_data.corr(), square=False,cmap='BuPu',annot=True)

g =sns.scatterplot(x="ApplicantIncome", y="LoanAmount",
              hue="Loan_Status",
              data=data);
g.set(xscale="log");

g =sns.scatterplot(x="CoapplicantIncome", y="LoanAmount",
              hue="Loan_Status",
              data=data);
g.set(xscale="log");

sns.scatterplot(data=data, x="CoapplicantIncome", y="LoanAmount")

"""## pre processing

Dropping the unnecessary columns
"""

data.drop('Loan_ID', inplace=True, axis='columns')

data.drop('CoapplicantIncome', inplace=True, axis='columns')

"""### data cleaning

"""

[features for features in data.columns if data[features].isnull().sum()>0]

df = data# give your dataframe name
missing_value= df.isnull().sum() 
percentage = (100 * df.isnull().sum() / len(df)).round(2).sort_values() 
data_types = df.dtypes
missing_values_table = pd.concat([missing_value, percentage, data_types], axis=1)
miss_val = missing_values_table.rename(columns = {0 : 'Missing Values',1 : 'Percentage',2 : 'Data Types'})
miss_vals=miss_val.sort_values(by='Percentage',ascending=False)
miss_vals1=miss_vals[miss_vals["Missing Values"]!=0]
miss_vals1

df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)
df['Married'].fillna(df['Married'].mode()[0], inplace=True)
df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)
df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)
df['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)

df.skew()

df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)
df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].median(), inplace=True)

df.isnull().sum()

"""## Handling Outliers"""

plt.boxplot([df.LoanAmount])
plt.title("Box Plot - LoanAmount")

print("10th percentile: ")
print(df['LoanAmount'].quantile(0.10))
print("90th percentile: ")
print(df['LoanAmount'].quantile(0.90))

df['LoanAmount'] = np.where(data['LoanAmount']>229.0, 229.0, data['LoanAmount'])

def box_plot(df):
    plt.figure(figsize=(12,8))
    plt.boxplot(df, vert=False)
    plt.title("Detecting outliers")
    plt.show()

print("After removing outliers >90th percentile: :")
box_plot(df['LoanAmount'])

sns.histplot(data=data, x="LoanAmount", kde=True, color='orange');
plt.axvline(x=data.LoanAmount.mean(), color='red')
plt.axvline(x=df.LoanAmount.median(), color='green')

df['LoanAmount'].skew()

"""## Skewed Distribution Treatment"""

df.ApplicantIncome = np.log(df.ApplicantIncome)

sns.histplot(data=df, x="ApplicantIncome", kde=True, color='orange');
plt.axvline(x=df.ApplicantIncome.mean(), color='red')
plt.axvline(x=df.ApplicantIncome.median(), color='green')

print(df['ApplicantIncome'].skew())

"""## Lable Encoding"""

from sklearn.preprocessing import LabelEncoder
cols = ['Gender', 'Married','Education','Self_Employed','Property_Area','Loan_Status', 'Dependents']
le = LabelEncoder()
for col in cols:
    df[col]= le.fit_transform(df[col])

df.head()

df['Dependents'].unique()

df['Property_Area'].unique()

X = df.drop(["Loan_Status"], axis=1)
y = df["Loan_Status"]

X.head()

y.head()

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=0)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""### Train model on data"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

from sklearn.model_selection import cross_val_score


# Support Vector Machine
svc = SVC()
svc.fit(X_train, y_train)
svc_score = cross_val_score(svc, X_train, y_train,cv=5)
print("Support Vector Machine: ", round(svc_score.mean(),2)*100, "% accuracy score")

"""Model accuracy score with default hyperparameters: 0.9827

### SVM with Linear kernel
"""

# instantiate classifier with linear kernel and C=1.0
linear_svc=SVC(kernel='linear', C=1.0) 

linear_svc.fit(X_train,y_train)

y_pred_test=linear_svc.predict(X_test)

print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))

# instantiate classifier with linear kernel and C=100.0
linear_svc100=SVC(kernel='linear', C=100.0) 

linear_svc100.fit(X_train, y_train)

y_pred=linear_svc100.predict(X_test)

print('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

# instantiate classifier with linear kernel and C=1000.0
linear_svc1000=SVC(kernel='linear', C=1000.0) 

linear_svc1000.fit(X_train, y_train)

y_pred=linear_svc1000.predict(X_test)

print('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

y_pred_train = linear_svc.predict(X_train)

y_pred_train

print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))

# Check for overfitting

print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))

print('Test set score: {:.4f}'.format(linear_svc.score(X_test, y_test)))

# check class distribution in test set

y_test.value_counts()

# check null accuracy score

null_accuracy = (3306/(3306+274))

print('Null accuracy score: {0:0.4f}'. format(null_accuracy))

"""### SVM with polynomial kernel"""

# instantiate classifier with polynomial kernel and C=1.0
poly_svc1=SVC(kernel='poly', C=1.0) 

poly_svc1.fit(X_train,y_train)

y_pred=poly_svc1.predict(X_test)

print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

# instantiate classifier with polynomial kernel and C=100.0
poly_svc100=SVC(kernel='poly', C=100.0) 

poly_svc100.fit(X_train, y_train)

y_pred=poly_svc100.predict(X_test)

print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""### SVM with sigmoid kernal"""

# instantiate classifier with sigmoid kernel and C=1.0
sigmoid_svc=SVC(kernel='sigmoid', C=1.0) 

sigmoid_svc.fit(X_train,y_train)

y_pred=sigmoid_svc.predict(X_test)

print('Model accuracy score with sigmoid kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

# instantiate classifier with sigmoid kernel and C=100.0
sigmoid_svc100=SVC(kernel='sigmoid', C=100.0) 

sigmoid_svc100.fit(X_train,y_train)

y_pred=sigmoid_svc100.predict(X_test)

print('Model accuracy score with sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""## Model evaluation"""

# SVC
svc_params = {'C':[0.5,1], 'kernel':['rbf','sigmoid']}
grid_svc = GridSearchCV(SVC(), svc_params)
grid_svc.fit(X_train, y_train)
svc = grid_svc.best_params_
print(svc)

# Support Vector Machine
svc = SVC(C= 0.5, kernel= 'rbf', probability=True)
svc.fit(X_train, y_train)
svc_score = cross_val_score(svc, X_train, y_train,cv=5)
print("Support Vector Machine: ", round(svc_score.mean(),2)*100, "% accuracy score")


sigmoid_svc=SVC(kernel='sigmoid', C=1.0) 
sigmoid_svc.fit(X_train,y_train)
sigmoid_svc_score = cross_val_score(svc, X_train, y_train,cv=5)
print("Support Vector Machine: ", round(sigmoid_svc_score.mean(),2)*100, "% accuracy score")

"""## Model Selection:

### Confusion matrix
"""

# Print the Confusion Matrix and slice it into four pieces(svm_linear_kernal)

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred_test)

print('Confusion matrix\n\n', cm)

print('\nTrue Positives(TP) = ', cm[0,0])

print('\nTrue Negatives(TN) = ', cm[1,1])

print('\nFalse Positives(FP) = ', cm[0,1])

print('\nFalse Negatives(FN) = ', cm[1,0])

"""The confusion matrix shows 3289 + 230 = 3519 correct predictions and 17 + 44 = 61 incorrect predictions.

In this case, we have

True Positives (Actual Positive:1 and Predict Positive:1) - 3289
True Negatives (Actual Negative:0 and Predict Negative:0) - 230
False Positives (Actual Negative:0 but Predict Positive:1) - 17 (Type I error)
False Negatives (Actual Positive:1 but Predict Negative:0) - 44 (Type II error)
"""

# visualize confusion matrix with seaborn heatmap

cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], 
                                 index=['Predict Positive:1', 'Predict Negative:0'])

sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')

"""### Classification Report"""

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_test))

TP = cm[0,0]
TN = cm[1,1]
FP = cm[0,1]
FN = cm[1,0]

# print classification accuracy

classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)

print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))

# print precision score

precision = TP / float(TP + FP)


print('Precision : {0:0.4f}'.format(precision))

recall = TP / float(TP + FN)

print('Recall or Sensitivity : {0:0.4f}'.format(recall))

"""### ROC and AUC"""

# plot ROC Curve

from sklearn.metrics import roc_curve

fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)

plt.figure(figsize=(6,4))

plt.plot(fpr, tpr, linewidth=2)

plt.plot([0,1], [0,1], 'k--' )

plt.rcParams['font.size'] = 12

plt.title('ROC curve for Predicting a Pulsar Star classifier')

plt.xlabel('False Positive Rate (1 - Specificity)')

plt.ylabel('True Positive Rate (Sensitivity)')

plt.show()

"""In the ROC Curve, we will focus on the TPR (True Positive Rate) and FPR (False Positive Rate) of a single point. This will give us the general performance of the ROC curve which consists of the TPR and FPR at various threshold levels. So, an ROC Curve plots TPR vs FPR at different classification threshold levels. If we lower the threshold levels, it may result in more items being classified as positve. It will increase both True Positives (TP) and False Positives (FP)."""

# compute ROC AUC

from sklearn.metrics import roc_auc_score

ROC_AUC = roc_auc_score(y_test, y_pred_test)

print('ROC AUC : {:.4f}'.format(ROC_AUC))

"""Inferences


ROC AUC is a single number summary of classifier performance. The higher the value, the better the classifier.

ROC AUC of our model approaches towards 1. So, we can conclude that our classifier does a good job in classifying the pulsar star.

CONCLUSION


=>There are outliers in our dataset. So, as I increase the value of C to limit fewer outliers, the accuracy increased. This is true with different kinds of kernels.

=>We get maximum accuracy with rbf and linear kernel with C=100.0 and the accuracy is 0.9832. So, we can conclude that our model is doing a very good job in terms of predicting the class labels. But, this is not true. Here, we have an imbalanced dataset. Accuracy is an inadequate measure for quantifying predictive performance in the imbalanced dataset problem. So, we must explore confusion matrix that provide better guidance in selecting models.

=>ROC AUC of our model is very close to 1. So, we can conclude that our classifier does a good job in classifying the pulsar star.
"""